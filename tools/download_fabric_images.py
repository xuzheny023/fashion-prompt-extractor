# -*- coding: utf-8 -*-
"""
Fabric image downloader - Download reference images from URLs
é¢æ–™å›¾ç‰‡ä¸‹è½½å™¨ - ä»URLæ‰¹é‡ä¸‹è½½å‚è€ƒå›¾ç‰‡
"""
from __future__ import annotations
import requests
from pathlib import Path
from PIL import Image
from io import BytesIO
import time

def download_image(url: str, save_path: Path, timeout: int = 10) -> bool:
    """
    ä»URLä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜
    
    Args:
        url: å›¾ç‰‡URL
        save_path: ä¿å­˜è·¯å¾„
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        
        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾ç‰‡
        img = Image.open(BytesIO(response.content))
        img.verify()
        
        # é‡æ–°æ‰“å¼€å¹¶è½¬æ¢ä¸ºRGB
        img = Image.open(BytesIO(response.content)).convert('RGB')
        
        # ä¿å­˜ä¸ºJPG
        img.save(save_path, 'JPEG', quality=95)
        return True
        
    except Exception as e:
        print(f"    âœ— Failed: {str(e)[:60]}")
        return False

def download_from_urls_file(fabric_name: str, urls_file: Path = None):
    """
    ä»URLåˆ—è¡¨æ–‡ä»¶ä¸‹è½½å›¾ç‰‡
    
    æ–‡ä»¶æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªURLï¼‰ï¼š
    https://example.com/image1.jpg
    https://example.com/image2.jpg
    """
    if urls_file is None:
        urls_file = Path(f"data/fabrics/{fabric_name}/urls.txt")
    
    if not urls_file.exists():
        print(f"âœ— URLs file not found: {urls_file}")
        return
    
    fabric_dir = Path(f"data/fabrics/{fabric_name}")
    fabric_dir.mkdir(parents=True, exist_ok=True)
    
    # è¯»å–URLåˆ—è¡¨
    with open(urls_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    print(f"\n[{fabric_name}] Downloading {len(urls)} images...")
    
    success = 0
    failed = 0
    
    for i, url in enumerate(urls, 1):
        # ç”Ÿæˆæ–‡ä»¶å
        save_path = fabric_dir / f"{fabric_name}_{i:03d}.jpg"
        
        # å¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡
        if save_path.exists():
            print(f"  [{i}/{len(urls)}] Skipped (already exists)")
            success += 1
            continue
        
        print(f"  [{i}/{len(urls)}] Downloading from {url[:50]}... ", end="", flush=True)
        
        if download_image(url, save_path):
            print("âœ“")
            success += 1
        else:
            failed += 1
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(0.5)
    
    print(f"\n  Summary: âœ“ {success} success, âœ— {failed} failed")
    return success, failed

def batch_download():
    """æ‰¹é‡ä¸‹è½½æ‰€æœ‰æœ‰urls.txtçš„é¢æ–™ç±»åˆ«"""
    fabrics_dir = Path("data/fabrics")
    
    print("="*60)
    print("Batch Fabric Image Downloader")
    print("="*60)
    
    # æŸ¥æ‰¾æ‰€æœ‰æœ‰urls.txtçš„ç±»åˆ«
    url_files = list(fabrics_dir.glob("*/urls.txt"))
    
    if not url_files:
        print("\nâœ— No urls.txt files found in fabric directories")
        print("\nğŸ’¡ Usage:")
        print("   1. Create urls.txt in each fabric folder:")
        print("      data/fabrics/denim/urls.txt")
        print("      data/fabrics/silk/urls.txt")
        print("   2. Add image URLs (one per line)")
        print("   3. Run this script")
        return
    
    print(f"\nFound {len(url_files)} fabric categories with URLs")
    
    total_success = 0
    total_failed = 0
    
    for url_file in sorted(url_files):
        fabric_name = url_file.parent.name
        success, failed = download_from_urls_file(fabric_name, url_file)
        total_success += success
        total_failed += failed
    
    print("\n" + "="*60)
    print(f"Total: âœ“ {total_success} downloaded, âœ— {total_failed} failed")
    print("="*60)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # ä¸‹è½½å•ä¸ªç±»åˆ«
        fabric_name = sys.argv[1]
        download_from_urls_file(fabric_name)
    else:
        # æ‰¹é‡ä¸‹è½½
        batch_download()


