# -*- coding: utf-8 -*-
"""
æ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•ç›®æ ‡ï¼š
- å•æ¬¡æ£€ç´¢ < 500ms (CPU)
- retrieve_topk è¿”å› List[ScoreItem]

ç”¨æ³•:
    python tools/benchmark_retrieval.py [å›¾ç‰‡è·¯å¾„] [--runs 10]
"""
import sys
import time
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
from PIL import Image

from src.fabric_clip_ranker import retrieve_topk, load_centroids, load_bank
from src.dual_clip import image_to_emb
from src.types import ScoreItem
from src.utils.logger import get_logger

log = get_logger("benchmark")

def benchmark_retrieval(image_path: Path, num_runs: int = 10):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    print("=" * 70)
    print("æ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 70)
    
    # 1. åŠ è½½å›¾ç‰‡
    print(f"\nğŸ“· æµ‹è¯•å›¾ç‰‡: {image_path}")
    try:
        img = Image.open(image_path)
        print(f"  âœ“ å›¾ç‰‡å¤§å°: {img.size[0]}x{img.size[1]}")
    except Exception as e:
        print(f"  âœ— å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. é¢„çƒ­ï¼ˆé¦–æ¬¡åŠ è½½æ¨¡å‹å’Œå‘é‡åº“ï¼‰
    print("\nğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
    print("  â†’ åŠ è½½ CLIP ç¼–ç å™¨...")
    t0 = time.perf_counter()
    query_emb = image_to_emb(img)
    warmup_encode_ms = (time.perf_counter() - t0) * 1000
    print(f"  âœ“ ç¼–ç å®Œæˆ: {warmup_encode_ms:.0f}ms (é¦–æ¬¡åŒ…å«æ¨¡å‹åŠ è½½)")
    
    print("  â†’ åŠ è½½å‘é‡åº“...")
    t0 = time.perf_counter()
    _ = load_centroids()
    _ = load_bank()
    warmup_load_ms = (time.perf_counter() - t0) * 1000
    print(f"  âœ“ å‘é‡åº“åŠ è½½: {warmup_load_ms:.0f}ms")
    
    print("  â†’ é¢„çƒ­æ£€ç´¢...")
    t0 = time.perf_counter()
    results, coarse_max = retrieve_topk(query_emb)
    warmup_retrieve_ms = (time.perf_counter() - t0) * 1000
    print(f"  âœ“ é¢„çƒ­æ£€ç´¢: {warmup_retrieve_ms:.0f}ms")
    
    # 3. éªŒè¯è¿”å›ç±»å‹
    print("\nâœ… éªŒè¯è¿”å›ç±»å‹...")
    if not isinstance(results, list):
        print(f"  âœ— è¿”å›ç±»å‹é”™è¯¯: æœŸæœ› list, å®é™… {type(results)}")
        return False
    if not results:
        print("  âœ— è¿”å›ç»“æœä¸ºç©º")
        return False
    if not isinstance(results[0], ScoreItem):
        print(f"  âœ— å…ƒç´ ç±»å‹é”™è¯¯: æœŸæœ› ScoreItem, å®é™… {type(results[0])}")
        return False
    print(f"  âœ“ è¿”å›ç±»å‹æ­£ç¡®: List[ScoreItem]")
    print(f"  âœ“ ç»“æœæ•°é‡: {len(results)}")
    print(f"  âœ“ Top 1: {results[0].label} ({results[0].score:.3f})")
    print(f"  âœ“ ç²—æ’æœ€é«˜åˆ†: {coarse_max:.3f}")
    
    # 4. æ€§èƒ½æµ‹è¯•ï¼ˆå¤šæ¬¡è¿è¡Œï¼‰
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯• ({num_runs} æ¬¡è¿è¡Œ)...")
    print("-" * 70)
    
    encode_times = []
    retrieve_times = []
    total_times = []
    
    for i in range(num_runs):
        # ç¼–ç 
        t0 = time.perf_counter()
        query_emb = image_to_emb(img)
        encode_ms = (time.perf_counter() - t0) * 1000
        encode_times.append(encode_ms)
        
        # æ£€ç´¢
        t0 = time.perf_counter()
        results, coarse_max = retrieve_topk(query_emb)
        retrieve_ms = (time.perf_counter() - t0) * 1000
        retrieve_times.append(retrieve_ms)
        
        total_ms = encode_ms + retrieve_ms
        total_times.append(total_ms)
        
        print(f"  Run {i+1:2d}: ç¼–ç ={encode_ms:5.0f}ms, æ£€ç´¢={retrieve_ms:5.0f}ms, æ€»è®¡={total_ms:5.0f}ms")
    
    # 5. ç»Ÿè®¡åˆ†æ
    print("\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print("-" * 70)
    
    def stats(times, name):
        mean = np.mean(times)
        std = np.std(times)
        min_t = np.min(times)
        max_t = np.max(times)
        median = np.median(times)
        
        print(f"\n{name}:")
        print(f"  å¹³å‡: {mean:.1f}ms")
        print(f"  ä¸­ä½æ•°: {median:.1f}ms")
        print(f"  æ ‡å‡†å·®: {std:.1f}ms")
        print(f"  èŒƒå›´: {min_t:.1f}ms - {max_t:.1f}ms")
        
        return mean
    
    encode_mean = stats(encode_times, "ç¼–ç æ—¶é—´")
    retrieve_mean = stats(retrieve_times, "æ£€ç´¢æ—¶é—´")
    total_mean = stats(total_times, "æ€»è€—æ—¶")
    
    # 6. æ€§èƒ½è¯„ä¼°
    print("\nğŸ¯ æ€§èƒ½è¯„ä¼°:")
    print("-" * 70)
    
    target_ms = 500
    passed = total_mean < target_ms
    
    if passed:
        print(f"  âœ… é€šè¿‡: å¹³å‡è€—æ—¶ {total_mean:.1f}ms < {target_ms}ms")
    else:
        print(f"  âš ï¸  æœªè¾¾æ ‡: å¹³å‡è€—æ—¶ {total_mean:.1f}ms >= {target_ms}ms")
    
    # æ€§èƒ½å»ºè®®
    print("\nğŸ’¡ æ€§èƒ½å»ºè®®:")
    if encode_mean > 200:
        print("  â€¢ ç¼–ç è¾ƒæ…¢ï¼Œè€ƒè™‘ä½¿ç”¨ GPU åŠ é€Ÿ")
    if retrieve_mean > 200:
        print("  â€¢ æ£€ç´¢è¾ƒæ…¢ï¼Œè€ƒè™‘:")
        print("    - å®‰è£… FAISS: pip install faiss-cpu")
        print("    - å‡å°‘ TOPC å‚æ•°ï¼ˆé»˜è®¤ 12ï¼‰")
        print("    - å‡å°‘æ ·æœ¬æ•°é‡")
    if total_mean < 200:
        print("  â€¢ âœ¨ æ€§èƒ½ä¼˜ç§€ï¼")
    
    print("\n" + "=" * 70)
    return passed


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯•")
    parser.add_argument("image", nargs="?", help="æµ‹è¯•å›¾ç‰‡è·¯å¾„")
    parser.add_argument("--runs", type=int, default=10, help="è¿è¡Œæ¬¡æ•°ï¼ˆé»˜è®¤ 10ï¼‰")
    
    args = parser.parse_args()
    
    # æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
    if args.image:
        test_image = Path(args.image)
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾
        fabrics_dir = Path("data/fabrics")
        test_image = None
        if fabrics_dir.exists():
            for img_file in fabrics_dir.rglob("*.jpg"):
                test_image = img_file
                break
    
    if not test_image or not test_image.exists():
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        print("\nç”¨æ³•: python tools/benchmark_retrieval.py [å›¾ç‰‡è·¯å¾„] [--runs 10]")
        sys.exit(1)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    success = benchmark_retrieval(test_image, num_runs=args.runs)
    
    sys.exit(0 if success else 1)

